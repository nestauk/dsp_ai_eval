{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Dict, Any\n",
    "from umap import UMAP\n",
    "\n",
    "from nesta_ds_utils.viz.altair import saving as viz_save\n",
    "from dsp_ai_eval.getters.scite import get_scite_df_w_embeddings\n",
    "from dsp_ai_eval.getters.gpt import get_gpt_themes_embeddings, get_cluster_summaries_cleaned\n",
    "\n",
    "from dsp_ai_eval import PROJECT_DIR, config\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "model = SentenceTransformer(config[\"embedding_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_most_similar_abstracts(gpt_cluster_summaries: pd.DataFrame, \n",
    "                                 abstracts: pd.DataFrame, \n",
    "                                 n: int = 3) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Finds the n most similar abstracts for each cluster represented in the GPT cluster summaries.\n",
    "    \n",
    "    For each cluster, it takes the most representative document in that cluster (ie a GPT-generated sentence). Then it computes the cosine\n",
    "    similarity between that document's embedding and the embeddings of all the abstracts.\n",
    "\n",
    "    It returns a dictionary where each key is a topic name from the \n",
    "    GPT cluster summaries, and the value is a DataFrame containing the top n most similar abstracts, \n",
    "    along with their similarity scores and assigned topic.\n",
    "\n",
    "    Parameters:\n",
    "    - gpt_cluster_summaries (pd.DataFrame): A DataFrame with at least two columns: 'representative_docs' \n",
    "      which contains the representative documents for each cluster, and 'topic_name' which contains the name \n",
    "      of the topic associated with each cluster.\n",
    "    - abstracts (pd.DataFrame): A DataFrame containing the abstracts with their embeddings in a column named \n",
    "      'embeddings'. Each embedding should be stored in a format that can be converted to a pandas Series.\n",
    "    - n (int, optional): The number of similar abstracts to retrieve for each topic. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "    - Dict[str, pd.DataFrame]: A dictionary mapping each topic name to a DataFrame containing the top n similar \n",
    "      abstracts, with additional columns 'topic' and 'similarity' for the topic name and similarity score, respectively.\n",
    "    \"\"\"\n",
    "    most_similar_abstracts = {}\n",
    "\n",
    "    for _, row in gpt_cluster_summaries.iterrows():\n",
    "        doc = ast.literal_eval(row['representative_docs'])[0]\n",
    "        reference_embedding = model.encode(doc)\n",
    "        similarities = [cosine_similarity([reference_embedding], [embed])[0][0] for embed in abstracts['embeddings'].apply(pd.Series).values]\n",
    "        top_indices = np.argsort(similarities)[::-1][:n]\n",
    "        similar_abstracts = abstracts.iloc[top_indices]\n",
    "        similar_abstracts['topic'] = row['topic_name']\n",
    "        similar_abstracts['similarity'] = [similarities[i] for i in top_indices]\n",
    "        \n",
    "        most_similar_abstracts[row['topic_name']] = similar_abstracts\n",
    "        \n",
    "    return most_similar_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_long = get_gpt_themes_embeddings()\n",
    "abstracts = get_scite_df_w_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the two datasets so that they have the same columns, then concatenate them\n",
    "abstracts = abstracts[['title_abstract', 'embeddings', 'total_cites']]\n",
    "abstracts = abstracts.rename(columns={'title_abstract': 'doc'})\n",
    "abstracts['gpt_model'] = 'research abstract'\n",
    "abstracts['temperature'] = 'NA'\n",
    "abstracts['source'] = 'abstract'\n",
    "abstracts = abstracts[['doc', 'embeddings', 'total_cites', 'gpt_model', 'temperature', 'source']]\n",
    "\n",
    "answers_long = answers_long[['answer_cleaned', 'embeddings', 'gpt_model', 'temperature']]\n",
    "answers_long['embeddings'] = answers_long['embeddings'].apply(ast.literal_eval)\n",
    "answers_long = answers_long.rename(columns={'answer_cleaned': 'doc'})\n",
    "answers_long['total_cites'] = 0\n",
    "answers_long['source'] = 'gpt'\n",
    "answers_long = answers_long[['doc', 'embeddings', 'total_cites', 'gpt_model', 'temperature', 'source']]\n",
    "\n",
    "all_data = pd.concat([abstracts, answers_long], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = all_data['embeddings'].apply(pd.Series).values\n",
    "\n",
    "umap_2d = UMAP(random_state=42)\n",
    "embeddings_2d = umap_2d.fit_transform(embeddings)\n",
    "\n",
    "df_vis = pd.DataFrame(embeddings_2d, columns=[\"x\", \"y\"])\n",
    "\n",
    "df_vis = pd.concat([all_data, df_vis], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vis['gpt_model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opacity_condition = alt.condition(\n",
    "            alt.datum.gpt_model == \"research abstract\", alt.value(1), alt.value(0.2)\n",
    "        )\n",
    "\n",
    "color_scale = alt.Scale(domain=['gpt-3.5-turbo', 'gpt-4', 'research abstract'],\n",
    "                        range=['#0d0887', '#7e03a8',\n",
    "                               #'#cc4778',\n",
    "                               '#f0f921'\n",
    "                               ])\n",
    "\n",
    "scatter_plot = alt.Chart(df_vis).mark_circle(size=100).encode(\n",
    "    x=alt.X('x:Q', axis=alt.Axis(ticks=False, labels=False, title=None)),\n",
    "    y=alt.Y('y:Q', axis=alt.Axis(ticks=False, labels=False, title=None)),\n",
    "    color=alt.Color('gpt_model', scale=color_scale),\n",
    "    opacity=opacity_condition,\n",
    "    tooltip=['source','gpt_model', 'doc']\n",
    ").configure_legend(title=None, labelFontSize=20, titleFontSize=20).properties(width=800, height=600).interactive()\n",
    "\n",
    "scatter_plot.save(PROJECT_DIR / f\"outputs/figures/gpt_abstracts_overlap.html\")\n",
    "viz_save.save(scatter_plot, f\"gpt_abstracts_overlap\", PROJECT_DIR / \"outputs/figures\", save_png=True)\n",
    "\n",
    "scatter_plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because in the previous plot it can be hard to see if GPT summaries are obscuring research abstracts, in the next plot, we scale the size of the points by number of citations. I would hypothesise that abstracts that have been cited hundreds of times should be more influential and therefore more likely to be similar to GPT summaries. So perhaps where there are small, seemingly outlying clusters of GPT summaries, maybe there are actually a couple of highly influential research papers nearby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a plot where point size is scaled by number of citations\n",
    "\n",
    "df_vis['size'] = df_vis['total_cites'].apply(lambda x: 100 if x == 0 else x*10)\n",
    "\n",
    "scatter_plot = alt.Chart(df_vis).mark_circle().encode(\n",
    "    x=alt.X('x:Q', axis=alt.Axis(ticks=False, labels=False, title=None)),\n",
    "    y=alt.Y('y:Q', axis=alt.Axis(ticks=False, labels=False, title=None)),\n",
    "    color='gpt_model',\n",
    "    size='size:Q',\n",
    "    opacity=alt.value(0.75),\n",
    "    tooltip=['source','gpt_model', 'doc']\n",
    ").properties(width=800, height=600).interactive()\n",
    "\n",
    "scatter_plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate most similar papers\n",
    "\n",
    "For each cluster of GPT summaries, find the N most similar research abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_cluster_summaries = get_cluster_summaries_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_abstracts = get_n_most_similar_abstracts(gpt_cluster_summaries, abstracts, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df = pd.concat(most_similar_abstracts.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(PROJECT_DIR / \"outputs/data/similar_abstracts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[concatenated_df['topic']=='International Technology Transfer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[concatenated_df['topic']=='Skill Development and Technology Diffusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp_ai_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
